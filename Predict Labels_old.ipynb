{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import dropbox\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "import math\n",
    "import collections\n",
    "from PIL import Image\n",
    "from dropbox import DropboxOAuth2FlowNoRedirect\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pypyodbc\n",
    "import sys\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import BatchNormalization, concatenate, Input, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical  #?\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pypyodbc.connect(\"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "                      \"Server=028-GUMUS1-SRV;\"\n",
    "                      \"Database=KOTON_DB;\"\n",
    "                      \"Trusted_Connection=yes;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token='0DQLcsXIojcAAAAAAAgybeB3DOmXKK7bRTLyYwkthbrAiGmpQR4AuGINQkjBXhif'\n",
    "dbx = dropbox.Dropbox(access_token)\n",
    "\n",
    "retrieved_image_df = pd.read_excel('C:/Users/Recep/Koton/Data/retrieved_image_list.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set(codes, indexes):\n",
    "    \"\"\"Takes list of option codes as input and returns related dataset, response set (sales amount)\n",
    "    and genuine option codes that included in e-commerce table.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(codes)>2000:\n",
    "        numOfBatches = 100\n",
    "    else:\n",
    "        numOfBatches = 1\n",
    "    \n",
    "    string_tar = \"SELECT [OptionCode] \\\n",
    "      ,[Groups] \\\n",
    "  FROM [KOTON_DB].[dbo].[Ratio_table_gruouped] Where (\"\n",
    "    \n",
    "    codes_split = np.array_split(codes, numOfBatches)\n",
    "    indexes_split = np.array_split(indexes, numOfBatches)\n",
    "    \n",
    "    # to prevent empty targets\n",
    "    gen_codes = []\n",
    "    gen_indexes = []\n",
    "    target = []\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        _ =[]\n",
    "        flag2 = True\n",
    "        for i in codes_split[batch]:\n",
    "            if flag2:\n",
    "                _.append(\"OptionCode='\"+i+\"'\")\n",
    "                flag2 = False\n",
    "            else:\n",
    "                 _.append(\" OR OptionCode='\"+i+\"'\")\n",
    "        query2 = string_tar + ''.join(_) + ')'\n",
    "        temp = pd.read_sql_query(query2, cnxn, index_col='optioncode')\n",
    "        target.append(temp)\n",
    "    target = pd.concat(target)\n",
    "\n",
    "    for code, index in zip(codes, indexes):\n",
    "        try:\n",
    "            target.loc[code]\n",
    "            gen_codes.append(code)\n",
    "            gen_indexes.append(index)\n",
    "        except:\n",
    "            pass        \n",
    "        \n",
    "    \n",
    "    string_inp = \"SELECT * \\\n",
    "  FROM [KOTON_DB].[dbo].[Input_table] \\\n",
    "  WHERE \"\n",
    "    \n",
    "#     numOfBatches = max(min(len(gen_indexes), numOfBatches), 1)\n",
    "    numOfBatches = max(min(len(gen_indexes), numOfBatches), 1)\n",
    "    gen_codes_splited = np.array_split(gen_codes, numOfBatches)\n",
    "    dataset = []\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        _ =[]\n",
    "        flag1 = True\n",
    "        for i in gen_codes_splited[batch]:\n",
    "            if flag1:\n",
    "                _.append(\"OptionCode='\"+i+\"'\")\n",
    "                flag1 = False\n",
    "            else:\n",
    "                 _.append(\" OR OptionCode='\"+i+\"'\")\n",
    "        query1 = string_inp + ''.join(_)\n",
    "        dataset.append(pd.read_sql_query(query1, cnxn, index_col='optioncode'))\n",
    "    \n",
    "    dataset = pd.concat(dataset)\n",
    "    \n",
    "    \n",
    "    return dataset, target, gen_codes, gen_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tarrain(numberSamples, startIndex, batchSize=64, return_data=False):\n",
    "    errorLog = []\n",
    "    bn_model = Xception(include_top=False, weights='imagenet', pooling='max')\n",
    "\n",
    "    first = bn_model.output\n",
    "    for layer in bn_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Dense(256, activation='relu')(first)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(10, activation='softmax')(model)\n",
    "\n",
    "    model_ = Model(inputs=[bn_model.input], outputs=model)\n",
    "\n",
    "    model_.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    codes = []\n",
    "    idx = []\n",
    "    for picture_index in range(startIndex,startIndex + numberSamples):\n",
    "        code = retrieved_image_df.iloc[picture_index].name\n",
    "        codes.append(code)\n",
    "        idx.append(picture_index)\n",
    "    \n",
    "    dset, tar, gen_codes, gen_indexes = data_set(codes, idx)\n",
    "#     dset = dset.apply(LabelEncoder().fit_transform)\n",
    "    dset = pd.get_dummies(dset)\n",
    "    tar = pd.get_dummies(tar)\n",
    "    print(dset.shape)\n",
    "    print(tar.shape)\n",
    "       \n",
    "    if batchSize>dset.shape[0]:\n",
    "        batchSize = dset.shape[0]\n",
    "        print('Batch size is automatically adjusted.')\n",
    "    \n",
    "    dset, dset_test, tar, tar_test = train_test_split(dset, tar, test_size=0.01, random_state=42)\n",
    "    gen_codes, gen_codes_test, gen_indexes, gen_indexes_test = train_test_split(gen_codes, gen_indexes, \n",
    "                                                                                test_size=0.01, random_state=42)\n",
    "    print(dset.shape)\n",
    "    \n",
    "    numOfBatches, lastBatch = divmod(dset.shape[0], batchSize-1)\n",
    "    dsets = np.array_split(dset, numOfBatches)\n",
    "    tars = np.array_split(tar, numOfBatches)\n",
    "    gen_codes = np.array_split(gen_codes, numOfBatches)\n",
    "    gen_indexes = np.array_split(gen_indexes, numOfBatches)\n",
    "    \n",
    "    valid_pic1 =[]\n",
    "    for code, picture_index in zip(gen_codes_test, gen_indexes_test):\n",
    "        im_index = retrieved_image_df.iloc[picture_index]['image1'+'_index']        \n",
    "        if (math.isnan(float(im_index))==False):\n",
    "            filename = str(code).lower()+'_'+'image1'+'_'+str(int(im_index))+'.jpg'\n",
    "            path = '/Koton_Image_Files/'+filename\n",
    "            try:\n",
    "                md, res = dbx.files_download(path)\n",
    "                temp_pic = cv2.cvtColor(cv2.resize(cv2.imdecode(np.frombuffer(res.content, dtype=np.uint8), -1), (299,299)), cv2.COLOR_BGR2RGB)\n",
    "                assert temp_pic.shape == (299, 299, 3)\n",
    "                valid_pic1.append(temp_pic)\n",
    "            except:\n",
    "                errorLog.append(path+' Not found')\n",
    "    valid_pic1 = preprocess_input(np.array(valid_pic1))\n",
    "#     valid_bottleneck_features = bn_model.predict(valid_pic1)\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        pic1 =[]\n",
    "        print('Batch: '+str(batch+1)+'/'+str(numOfBatches))\n",
    "        for code, picture_index in zip(gen_codes[batch], gen_indexes[batch]):\n",
    "            im_index = retrieved_image_df.iloc[picture_index]['image1'+'_index']        \n",
    "            if (math.isnan(float(im_index))==False):\n",
    "                filename = str(code).lower()+'_'+'image1'+'_'+str(int(im_index))+'.jpg'\n",
    "                path = '/Koton_Image_Files/'+filename\n",
    "                try:\n",
    "                    md, res = dbx.files_download(path)\n",
    "                    temp_pic = cv2.cvtColor(cv2.resize(cv2.imdecode(np.frombuffer(res.content, dtype=np.uint8), -1), (299,299)), cv2.COLOR_BGR2RGB)\n",
    "                    assert temp_pic.shape == (299, 299, 3)\n",
    "                    pic1.append(temp_pic)\n",
    "                except:\n",
    "                    errorLog.append(path+' Not found')\n",
    "                    batch += 1 #ignore defective batch\n",
    "        pic1 = preprocess_input(np.array(pic1))\n",
    "        try:\n",
    "            model_.fit(pic1, tars[batch], validation_data=(valid_pic1, tar_test), epochs=60)\n",
    "            if batch%3 ==0:\n",
    "                timestr = time.strftime(\"%Y%m%d\")\n",
    "                model_.save('model'+timestr+'.h5')\n",
    "        except:\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            errorLog.append(''.join('!! ' + line for line in lines))\n",
    "    if return_data:\n",
    "        return model_, errorLog, dset, dset_test, tar, tar_test, gen_codes, gen_codes_test, gen_indexes, gen_indexes_test\n",
    "    else:\n",
    "        return model_, errorLog\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 193)\n",
      "(6144, 10)\n",
      "(6082, 193)\n",
      "Batch: 1/96\n",
      "Train on 64 samples, validate on 62 samples\n",
      "Epoch 1/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 8.5426 - acc: 0.1562 - val_loss: 7.2880 - val_acc: 0.0968\n",
      "Epoch 2/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 9.2375 - acc: 0.2656 - val_loss: 8.1729 - val_acc: 0.1290\n",
      "Epoch 3/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 9.5140 - acc: 0.1719 - val_loss: 6.7239 - val_acc: 0.1129\n",
      "Epoch 4/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 7.0327 - acc: 0.2344 - val_loss: 5.7679 - val_acc: 0.1129\n",
      "Epoch 5/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 6.7272 - acc: 0.1406 - val_loss: 5.8762 - val_acc: 0.0806\n",
      "Epoch 6/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 7.1608 - acc: 0.1562 - val_loss: 4.9213 - val_acc: 0.0968\n",
      "Epoch 7/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 4.8422 - acc: 0.3125 - val_loss: 3.4644 - val_acc: 0.2419\n",
      "Epoch 8/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 4.6314 - acc: 0.2500 - val_loss: 2.7138 - val_acc: 0.1935\n",
      "Epoch 9/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 2.4765 - acc: 0.4219 - val_loss: 3.2455 - val_acc: 0.1613\n",
      "Epoch 10/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.9791 - acc: 0.5000 - val_loss: 2.4513 - val_acc: 0.2581\n",
      "Epoch 11/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.6248 - acc: 0.5156 - val_loss: 3.0695 - val_acc: 0.2097\n",
      "Epoch 12/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 2.1519 - acc: 0.4062 - val_loss: 2.8763 - val_acc: 0.1290\n",
      "Epoch 13/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2099 - acc: 0.6094 - val_loss: 2.5367 - val_acc: 0.1452\n",
      "Epoch 14/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0202 - acc: 0.6406 - val_loss: 2.6035 - val_acc: 0.1452\n",
      "Epoch 15/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.1029 - acc: 0.6250 - val_loss: 2.6164 - val_acc: 0.1774\n",
      "Epoch 16/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0060 - acc: 0.6875 - val_loss: 2.5704 - val_acc: 0.1935\n",
      "Epoch 17/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.7732 - acc: 0.7969 - val_loss: 2.5896 - val_acc: 0.1935\n",
      "Epoch 18/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0566 - acc: 0.6562 - val_loss: 3.0353 - val_acc: 0.1290\n",
      "Epoch 19/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.7722 - acc: 0.7500 - val_loss: 3.0447 - val_acc: 0.2097\n",
      "Epoch 20/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3401 - acc: 0.5938 - val_loss: 2.9015 - val_acc: 0.0968\n",
      "Epoch 21/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.6583 - acc: 0.7656 - val_loss: 2.7582 - val_acc: 0.1613\n",
      "Epoch 22/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.5634 - acc: 0.7969 - val_loss: 2.9880 - val_acc: 0.0806\n",
      "Epoch 23/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7720 - acc: 0.7188 - val_loss: 2.9796 - val_acc: 0.0806\n",
      "Epoch 24/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.6378 - acc: 0.8281 - val_loss: 2.4199 - val_acc: 0.1774\n",
      "Epoch 25/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5975 - acc: 0.7812 - val_loss: 3.0193 - val_acc: 0.1774\n",
      "Epoch 26/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.7572 - acc: 0.7188 - val_loss: 2.7890 - val_acc: 0.1935\n",
      "Epoch 27/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.4357 - acc: 0.5938 - val_loss: 3.8355 - val_acc: 0.1290\n",
      "Epoch 28/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.4664 - acc: 0.4531 - val_loss: 3.7560 - val_acc: 0.1452\n",
      "Epoch 29/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.6288 - acc: 0.5625 - val_loss: 3.0101 - val_acc: 0.1452\n",
      "Epoch 30/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.5497 - acc: 0.7812 - val_loss: 2.7576 - val_acc: 0.1129\n",
      "Epoch 31/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.4114 - acc: 0.8906 - val_loss: 2.8417 - val_acc: 0.1774\n",
      "Epoch 32/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.4161 - acc: 0.8750 - val_loss: 3.3757 - val_acc: 0.1290\n",
      "Epoch 33/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.3196 - acc: 0.9062 - val_loss: 3.0002 - val_acc: 0.1290\n",
      "Epoch 34/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.3064 - acc: 0.9375 - val_loss: 3.5262 - val_acc: 0.1129\n",
      "Epoch 35/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.2127 - acc: 0.9375 - val_loss: 3.0414 - val_acc: 0.1452\n",
      "Epoch 36/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.6498 - acc: 0.7656 - val_loss: 2.9044 - val_acc: 0.1613\n",
      "Epoch 37/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9323 - acc: 0.7500 - val_loss: 2.6475 - val_acc: 0.2258\n",
      "Epoch 38/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.4559 - acc: 0.7969 - val_loss: 2.8416 - val_acc: 0.2258\n",
      "Epoch 39/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.4551 - acc: 0.8594 - val_loss: 3.6377 - val_acc: 0.1774\n",
      "Epoch 40/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.6440 - acc: 0.7188 - val_loss: 4.1468 - val_acc: 0.1129\n",
      "Epoch 41/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5352 - acc: 0.8438 - val_loss: 3.2340 - val_acc: 0.1935\n",
      "Epoch 42/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.3261 - acc: 0.8594 - val_loss: 3.6096 - val_acc: 0.1129\n",
      "Epoch 43/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.1298 - acc: 0.9688 - val_loss: 3.3623 - val_acc: 0.1129\n",
      "Epoch 44/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.1858 - acc: 0.9219 - val_loss: 3.1793 - val_acc: 0.1613\n",
      "Epoch 45/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.0771 - acc: 1.0000 - val_loss: 3.0629 - val_acc: 0.1452\n",
      "Epoch 46/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.1239 - acc: 0.9844 - val_loss: 3.2977 - val_acc: 0.1774\n",
      "Epoch 47/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.1585 - acc: 0.9375 - val_loss: 4.1975 - val_acc: 0.0968\n",
      "Epoch 48/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.4880 - acc: 0.8750 - val_loss: 3.4053 - val_acc: 0.1129\n",
      "Epoch 49/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.2233 - acc: 0.9062 - val_loss: 4.3325 - val_acc: 0.1290\n",
      "Epoch 50/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.7522 - acc: 0.7344 - val_loss: 4.5427 - val_acc: 0.1452\n",
      "Epoch 51/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5070 - acc: 0.8281 - val_loss: 6.2267 - val_acc: 0.0806\n",
      "Epoch 52/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0825 - acc: 0.7500 - val_loss: 3.8452 - val_acc: 0.1129\n",
      "Epoch 53/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5933 - acc: 0.7969 - val_loss: 3.1155 - val_acc: 0.2258\n",
      "Epoch 54/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.2339 - acc: 0.9375 - val_loss: 3.3597 - val_acc: 0.1129\n",
      "Epoch 55/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.1581 - acc: 0.9688 - val_loss: 3.2599 - val_acc: 0.1774\n",
      "Epoch 56/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.0456 - acc: 1.0000 - val_loss: 3.3194 - val_acc: 0.1290\n",
      "Epoch 57/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.0480 - acc: 1.0000 - val_loss: 3.5856 - val_acc: 0.1774\n",
      "Epoch 58/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.1045 - acc: 0.9844 - val_loss: 3.6217 - val_acc: 0.1290\n",
      "Epoch 59/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.0673 - acc: 0.9844 - val_loss: 3.8223 - val_acc: 0.1452\n",
      "Epoch 60/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.1209 - acc: 0.9375 - val_loss: 3.8603 - val_acc: 0.1129\n",
      "Batch: 2/96\n",
      "Train on 64 samples, validate on 62 samples\n",
      "Epoch 1/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 5.7930 - acc: 0.1250 - val_loss: 3.5718 - val_acc: 0.1774\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 97s 2s/step - loss: 3.8523 - acc: 0.2500 - val_loss: 2.2693 - val_acc: 0.2097\n",
      "Epoch 3/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 2.2371 - acc: 0.2812 - val_loss: 2.1563 - val_acc: 0.2581\n",
      "Epoch 4/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.9422 - acc: 0.3438 - val_loss: 2.2302 - val_acc: 0.1774\n",
      "Epoch 5/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.0735 - acc: 0.2969 - val_loss: 2.2126 - val_acc: 0.1774\n",
      "Epoch 6/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.8536 - acc: 0.3906 - val_loss: 2.2160 - val_acc: 0.2258\n",
      "Epoch 7/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.9371 - acc: 0.4062 - val_loss: 2.3319 - val_acc: 0.1774\n",
      "Epoch 8/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.8908 - acc: 0.3438 - val_loss: 2.1806 - val_acc: 0.2581\n",
      "Epoch 9/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.6589 - acc: 0.4219 - val_loss: 2.3205 - val_acc: 0.2258\n",
      "Epoch 10/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.4129 - acc: 0.4688 - val_loss: 2.3596 - val_acc: 0.1452\n",
      "Epoch 11/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.3196 - acc: 0.5781 - val_loss: 2.3975 - val_acc: 0.2097\n",
      "Epoch 12/60\n",
      "64/64 [==============================] - 96s 2s/step - loss: 1.4742 - acc: 0.5156 - val_loss: 2.5046 - val_acc: 0.1613\n",
      "Epoch 13/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3535 - acc: 0.6094 - val_loss: 2.3751 - val_acc: 0.2258\n",
      "Epoch 14/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3133 - acc: 0.6094 - val_loss: 2.6156 - val_acc: 0.1452\n",
      "Epoch 15/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.2338 - acc: 0.6094 - val_loss: 2.6824 - val_acc: 0.1452\n",
      "Epoch 16/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2404 - acc: 0.5469 - val_loss: 2.5972 - val_acc: 0.0806\n",
      "Epoch 17/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1815 - acc: 0.5938 - val_loss: 2.4531 - val_acc: 0.1613\n",
      "Epoch 18/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0574 - acc: 0.6719 - val_loss: 2.5300 - val_acc: 0.1774\n",
      "Epoch 19/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1123 - acc: 0.6250 - val_loss: 2.3895 - val_acc: 0.1774\n",
      "Epoch 20/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.8826 - acc: 0.6875 - val_loss: 2.6155 - val_acc: 0.1452\n",
      "Epoch 21/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0790 - acc: 0.6406 - val_loss: 2.4906 - val_acc: 0.1613\n",
      "Epoch 22/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9299 - acc: 0.6719 - val_loss: 2.6034 - val_acc: 0.0806\n",
      "Epoch 23/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.8569 - acc: 0.6875 - val_loss: 2.4504 - val_acc: 0.1935\n",
      "Epoch 24/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8990 - acc: 0.6875 - val_loss: 2.6015 - val_acc: 0.1774\n",
      "Epoch 25/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.8218 - acc: 0.7031 - val_loss: 2.9140 - val_acc: 0.1613\n",
      "Epoch 26/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2803 - acc: 0.5312 - val_loss: 2.8744 - val_acc: 0.1452\n",
      "Epoch 27/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9307 - acc: 0.6406 - val_loss: 2.5490 - val_acc: 0.1452\n",
      "Epoch 28/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.7668 - acc: 0.7031 - val_loss: 2.7637 - val_acc: 0.1613\n",
      "Epoch 29/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7027 - acc: 0.7812 - val_loss: 2.7740 - val_acc: 0.1290\n",
      "Epoch 30/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.6809 - acc: 0.7656 - val_loss: 2.8837 - val_acc: 0.1774\n",
      "Epoch 31/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.6539 - acc: 0.7969 - val_loss: 2.8169 - val_acc: 0.1452\n",
      "Epoch 32/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.6440 - acc: 0.7656 - val_loss: 2.7292 - val_acc: 0.1774\n",
      "Epoch 33/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.6463 - acc: 0.7656 - val_loss: 2.9149 - val_acc: 0.1290\n",
      "Epoch 34/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.6500 - acc: 0.7656 - val_loss: 2.8580 - val_acc: 0.1129\n",
      "Epoch 35/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.6724 - acc: 0.7969 - val_loss: 3.1734 - val_acc: 0.1290\n",
      "Epoch 36/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7393 - acc: 0.7812 - val_loss: 3.1338 - val_acc: 0.1613\n",
      "Epoch 37/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.5546 - acc: 0.7812 - val_loss: 2.8515 - val_acc: 0.1774\n",
      "Epoch 38/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.3312 - acc: 0.9219 - val_loss: 3.0872 - val_acc: 0.1774\n",
      "Epoch 39/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.4320 - acc: 0.8438 - val_loss: 3.0080 - val_acc: 0.1613\n",
      "Epoch 40/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5337 - acc: 0.8594 - val_loss: 2.8220 - val_acc: 0.1774\n",
      "Epoch 41/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0859 - acc: 0.6250 - val_loss: 2.7988 - val_acc: 0.1935\n",
      "Epoch 42/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5488 - acc: 0.7812 - val_loss: 2.9593 - val_acc: 0.1452\n",
      "Epoch 43/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5300 - acc: 0.7969 - val_loss: 3.1188 - val_acc: 0.1129\n",
      "Epoch 44/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.4000 - acc: 0.9219 - val_loss: 3.0281 - val_acc: 0.1129\n",
      "Epoch 45/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.5706 - acc: 0.8281 - val_loss: 3.1079 - val_acc: 0.1935\n",
      "Epoch 46/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.2759 - acc: 0.9062 - val_loss: 3.1610 - val_acc: 0.1129\n",
      "Epoch 47/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.3292 - acc: 0.8906 - val_loss: 2.9219 - val_acc: 0.1935\n",
      "Epoch 48/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8573 - acc: 0.6875 - val_loss: 3.2968 - val_acc: 0.1774\n",
      "Epoch 49/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7116 - acc: 0.7344 - val_loss: 3.5305 - val_acc: 0.1774\n",
      "Epoch 50/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.5638 - acc: 0.7812 - val_loss: 3.0209 - val_acc: 0.1290\n",
      "Epoch 51/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.3596 - acc: 0.8594 - val_loss: 2.9485 - val_acc: 0.1290\n",
      "Epoch 52/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.2911 - acc: 0.9375 - val_loss: 3.3302 - val_acc: 0.1774\n",
      "Epoch 53/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.3083 - acc: 0.8594 - val_loss: 3.3184 - val_acc: 0.1774\n",
      "Epoch 54/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.2632 - acc: 0.9062 - val_loss: 3.2355 - val_acc: 0.1290\n",
      "Epoch 55/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.2530 - acc: 0.9062 - val_loss: 3.4364 - val_acc: 0.1452\n",
      "Epoch 56/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.3612 - acc: 0.9062 - val_loss: 3.7431 - val_acc: 0.0968\n",
      "Epoch 57/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.3876 - acc: 0.8281 - val_loss: 3.2228 - val_acc: 0.1290\n",
      "Epoch 58/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.3207 - acc: 0.9062 - val_loss: 3.3159 - val_acc: 0.1290\n",
      "Epoch 59/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.3305 - acc: 0.8906 - val_loss: 3.7112 - val_acc: 0.0806\n",
      "Epoch 60/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.2875 - acc: 0.8750 - val_loss: 3.8526 - val_acc: 0.0968\n",
      "Batch: 3/96\n",
      "Train on 64 samples, validate on 62 samples\n",
      "Epoch 1/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 4.1811 - acc: 0.2188 - val_loss: 2.3911 - val_acc: 0.1774\n",
      "Epoch 2/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 2.3136 - acc: 0.1875 - val_loss: 2.3542 - val_acc: 0.1129\n",
      "Epoch 3/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.3769 - acc: 0.2031 - val_loss: 2.3040 - val_acc: 0.0806\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 96s 2s/step - loss: 2.2623 - acc: 0.2656 - val_loss: 2.3375 - val_acc: 0.1290\n",
      "Epoch 5/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 2.1261 - acc: 0.2188 - val_loss: 2.2226 - val_acc: 0.1935\n",
      "Epoch 6/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.9912 - acc: 0.2031 - val_loss: 2.2196 - val_acc: 0.1613\n",
      "Epoch 7/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.8629 - acc: 0.2969 - val_loss: 2.1962 - val_acc: 0.2419\n",
      "Epoch 8/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.9849 - acc: 0.2656 - val_loss: 2.3107 - val_acc: 0.1290\n",
      "Epoch 9/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.8429 - acc: 0.2812 - val_loss: 2.2774 - val_acc: 0.1774\n",
      "Epoch 10/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.8396 - acc: 0.3906 - val_loss: 2.2095 - val_acc: 0.1452\n",
      "Epoch 11/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.7448 - acc: 0.3281 - val_loss: 2.2079 - val_acc: 0.1129\n",
      "Epoch 12/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.7953 - acc: 0.3438 - val_loss: 2.2595 - val_acc: 0.1129\n",
      "Epoch 13/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.5181 - acc: 0.4375 - val_loss: 2.2523 - val_acc: 0.1613\n",
      "Epoch 14/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.6889 - acc: 0.3125 - val_loss: 2.2979 - val_acc: 0.1452\n",
      "Epoch 15/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.7370 - acc: 0.3594 - val_loss: 2.2005 - val_acc: 0.1290\n",
      "Epoch 16/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.5961 - acc: 0.3438 - val_loss: 2.2770 - val_acc: 0.1613\n",
      "Epoch 17/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.5454 - acc: 0.4375 - val_loss: 2.3228 - val_acc: 0.1452\n",
      "Epoch 18/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2994 - acc: 0.4375 - val_loss: 2.3117 - val_acc: 0.1290\n",
      "Epoch 19/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3891 - acc: 0.4688 - val_loss: 2.3617 - val_acc: 0.1935\n",
      "Epoch 20/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.4793 - acc: 0.5000 - val_loss: 2.3238 - val_acc: 0.1613\n",
      "Epoch 21/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.3662 - acc: 0.5625 - val_loss: 2.3259 - val_acc: 0.1129\n",
      "Epoch 22/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.3279 - acc: 0.4531 - val_loss: 2.2978 - val_acc: 0.1613\n",
      "Epoch 23/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.2767 - acc: 0.5312 - val_loss: 2.4078 - val_acc: 0.1452\n",
      "Epoch 24/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.3648 - acc: 0.3750 - val_loss: 2.2362 - val_acc: 0.1774\n",
      "Epoch 25/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.3219 - acc: 0.5312 - val_loss: 2.3123 - val_acc: 0.1129\n",
      "Epoch 26/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.0977 - acc: 0.5938 - val_loss: 2.3878 - val_acc: 0.1452\n",
      "Epoch 27/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.2470 - acc: 0.5938 - val_loss: 2.3871 - val_acc: 0.1290\n",
      "Epoch 28/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.4554 - acc: 0.3906 - val_loss: 2.2833 - val_acc: 0.1613\n",
      "Epoch 29/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.1466 - acc: 0.6406 - val_loss: 2.4368 - val_acc: 0.1452\n",
      "Epoch 30/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.2208 - acc: 0.5625 - val_loss: 2.3713 - val_acc: 0.1290\n",
      "Epoch 31/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.0727 - acc: 0.5938 - val_loss: 2.4153 - val_acc: 0.0806\n",
      "Epoch 32/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.2045 - acc: 0.5938 - val_loss: 2.4957 - val_acc: 0.1452\n",
      "Epoch 33/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 0.9117 - acc: 0.6562 - val_loss: 2.5331 - val_acc: 0.1774\n",
      "Epoch 34/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.0223 - acc: 0.5938 - val_loss: 2.4585 - val_acc: 0.1774\n",
      "Epoch 35/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 0.9657 - acc: 0.6719 - val_loss: 2.4504 - val_acc: 0.1613\n",
      "Epoch 36/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.0841 - acc: 0.6406 - val_loss: 2.4585 - val_acc: 0.1452\n",
      "Epoch 37/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.0811 - acc: 0.6094 - val_loss: 2.6290 - val_acc: 0.1935\n",
      "Epoch 38/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.0086 - acc: 0.6250 - val_loss: 2.5845 - val_acc: 0.1613\n",
      "Epoch 39/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3187 - acc: 0.5781 - val_loss: 2.5618 - val_acc: 0.1613\n",
      "Epoch 40/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.9485 - acc: 0.6562 - val_loss: 2.4766 - val_acc: 0.1774\n",
      "Epoch 41/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7635 - acc: 0.7500 - val_loss: 2.5794 - val_acc: 0.1290\n",
      "Epoch 42/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7181 - acc: 0.7500 - val_loss: 2.6266 - val_acc: 0.1452\n",
      "Epoch 43/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7779 - acc: 0.6875 - val_loss: 2.6204 - val_acc: 0.1290\n",
      "Epoch 44/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.8994 - acc: 0.6875 - val_loss: 2.6164 - val_acc: 0.1452\n",
      "Epoch 45/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.6855 - acc: 0.7656 - val_loss: 2.6074 - val_acc: 0.1613\n",
      "Epoch 46/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 0.7985 - acc: 0.7344 - val_loss: 2.5003 - val_acc: 0.1452\n",
      "Epoch 47/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.8419 - acc: 0.6719 - val_loss: 2.4974 - val_acc: 0.1774\n",
      "Epoch 48/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.8571 - acc: 0.6406 - val_loss: 2.5931 - val_acc: 0.1129\n",
      "Epoch 49/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.7969 - acc: 0.7031 - val_loss: 2.5826 - val_acc: 0.1774\n",
      "Epoch 50/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 0.6101 - acc: 0.8125 - val_loss: 2.5809 - val_acc: 0.1452\n",
      "Epoch 51/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.7859 - acc: 0.7031 - val_loss: 2.6287 - val_acc: 0.1290\n",
      "Epoch 52/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.7268 - acc: 0.7656 - val_loss: 2.5642 - val_acc: 0.1774\n",
      "Epoch 53/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 0.6402 - acc: 0.7812 - val_loss: 2.8174 - val_acc: 0.1774\n",
      "Epoch 54/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 0.6904 - acc: 0.7344 - val_loss: 2.8241 - val_acc: 0.2097\n",
      "Epoch 55/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 0.7786 - acc: 0.7188 - val_loss: 2.6912 - val_acc: 0.1774\n",
      "Epoch 56/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.7285 - acc: 0.6875 - val_loss: 2.4797 - val_acc: 0.1452\n",
      "Epoch 57/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.6176 - acc: 0.8594 - val_loss: 2.6879 - val_acc: 0.1452\n",
      "Epoch 58/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.5811 - acc: 0.7500 - val_loss: 2.6351 - val_acc: 0.1452\n",
      "Epoch 59/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.7750 - acc: 0.6562 - val_loss: 2.6033 - val_acc: 0.1774\n",
      "Epoch 60/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 0.6403 - acc: 0.7812 - val_loss: 2.7562 - val_acc: 0.1774\n",
      "Batch: 4/96\n",
      "Batch: 5/96\n",
      "Train on 64 samples, validate on 62 samples\n",
      "Epoch 1/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 3.4056 - acc: 0.1875 - val_loss: 2.1692 - val_acc: 0.1774\n",
      "Epoch 2/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 2.2758 - acc: 0.2188 - val_loss: 2.2611 - val_acc: 0.1613\n",
      "Epoch 3/60\n",
      "64/64 [==============================] - 109s 2s/step - loss: 2.1650 - acc: 0.2500 - val_loss: 2.2066 - val_acc: 0.2419\n",
      "Epoch 4/60\n",
      "64/64 [==============================] - 119s 2s/step - loss: 2.4034 - acc: 0.2188 - val_loss: 2.1555 - val_acc: 0.2581\n",
      "Epoch 5/60\n",
      "64/64 [==============================] - 113s 2s/step - loss: 1.8864 - acc: 0.3125 - val_loss: 2.1960 - val_acc: 0.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60\n",
      "64/64 [==============================] - 107s 2s/step - loss: 1.8590 - acc: 0.3125 - val_loss: 2.2143 - val_acc: 0.3226\n",
      "Epoch 7/60\n",
      "64/64 [==============================] - 103s 2s/step - loss: 1.9980 - acc: 0.2969 - val_loss: 2.1661 - val_acc: 0.2419\n",
      "Epoch 8/60\n",
      "64/64 [==============================] - 104s 2s/step - loss: 1.8708 - acc: 0.2812 - val_loss: 2.2734 - val_acc: 0.2097\n",
      "Epoch 9/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.8444 - acc: 0.3906 - val_loss: 2.2001 - val_acc: 0.2742\n",
      "Epoch 10/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.5881 - acc: 0.3906 - val_loss: 2.3436 - val_acc: 0.2419\n",
      "Epoch 11/60\n",
      "64/64 [==============================] - 100s 2s/step - loss: 1.7073 - acc: 0.4062 - val_loss: 2.2662 - val_acc: 0.2419\n",
      "Epoch 12/60\n",
      "64/64 [==============================] - 101s 2s/step - loss: 1.5124 - acc: 0.4688 - val_loss: 2.1926 - val_acc: 0.2903\n",
      "Epoch 13/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.5245 - acc: 0.4062 - val_loss: 2.3452 - val_acc: 0.2742\n",
      "Epoch 14/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.4713 - acc: 0.4375 - val_loss: 2.3403 - val_acc: 0.2419\n",
      "Epoch 15/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.5813 - acc: 0.4219 - val_loss: 2.3144 - val_acc: 0.2581\n",
      "Epoch 16/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.3274 - acc: 0.5625 - val_loss: 2.4361 - val_acc: 0.2581\n",
      "Epoch 17/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.4361 - acc: 0.4688 - val_loss: 2.2003 - val_acc: 0.1935\n",
      "Epoch 18/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.3274 - acc: 0.3906 - val_loss: 2.2055 - val_acc: 0.2903\n",
      "Epoch 19/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.3245 - acc: 0.4844 - val_loss: 2.2105 - val_acc: 0.3065\n",
      "Epoch 20/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.3127 - acc: 0.4062 - val_loss: 2.2439 - val_acc: 0.2903\n",
      "Epoch 21/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.2139 - acc: 0.6094 - val_loss: 2.4780 - val_acc: 0.2581\n",
      "Epoch 22/60\n",
      "32/64 [==============>...............] - ETA: 21s - loss: 1.1274 - acc: 0.5312Batch: 6/96\n",
      "Train on 64 samples, validate on 62 samples\n",
      "Epoch 1/60\n",
      "32/64 [==============>...............] - ETA: 21s - loss: 2.6133 - acc: 0.0625Batch: 7/96\n",
      "Train on 64 samples, validate on 62 samples\n",
      "Epoch 1/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 2.4891 - acc: 0.2969 - val_loss: 2.1605 - val_acc: 0.2419\n",
      "Epoch 2/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.1389 - acc: 0.2656 - val_loss: 2.1767 - val_acc: 0.2742\n",
      "Epoch 3/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.1851 - acc: 0.2656 - val_loss: 2.2173 - val_acc: 0.2258\n",
      "Epoch 4/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.2423 - acc: 0.1875 - val_loss: 2.1641 - val_acc: 0.2419\n",
      "Epoch 5/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 2.2468 - acc: 0.1250 - val_loss: 2.1344 - val_acc: 0.2581\n",
      "Epoch 6/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.0063 - acc: 0.1875 - val_loss: 2.2028 - val_acc: 0.2258\n",
      "Epoch 7/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.0309 - acc: 0.3281 - val_loss: 2.1545 - val_acc: 0.2581\n",
      "Epoch 8/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.0147 - acc: 0.2500 - val_loss: 2.1444 - val_acc: 0.2258\n",
      "Epoch 9/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.8719 - acc: 0.3125 - val_loss: 2.2221 - val_acc: 0.2419\n",
      "Epoch 10/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.9188 - acc: 0.2812 - val_loss: 2.1758 - val_acc: 0.2419\n",
      "Epoch 11/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.9172 - acc: 0.2969 - val_loss: 2.1581 - val_acc: 0.2742\n",
      "Epoch 12/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.7996 - acc: 0.2500 - val_loss: 2.2705 - val_acc: 0.2097\n",
      "Epoch 13/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.9807 - acc: 0.3125 - val_loss: 2.1074 - val_acc: 0.2419\n",
      "Epoch 14/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.7171 - acc: 0.3281 - val_loss: 2.2042 - val_acc: 0.2097\n",
      "Epoch 15/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.6604 - acc: 0.2969 - val_loss: 2.2851 - val_acc: 0.3065\n",
      "Epoch 16/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.9899 - acc: 0.3125 - val_loss: 2.1299 - val_acc: 0.2419\n",
      "Epoch 17/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.6194 - acc: 0.3750 - val_loss: 2.2529 - val_acc: 0.2258\n",
      "Epoch 18/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.6618 - acc: 0.4375 - val_loss: 2.1633 - val_acc: 0.2742\n",
      "Epoch 19/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.6993 - acc: 0.3281 - val_loss: 2.2656 - val_acc: 0.2258\n",
      "Epoch 20/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.5837 - acc: 0.4375 - val_loss: 2.2589 - val_acc: 0.2258\n",
      "Epoch 21/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.6109 - acc: 0.3438 - val_loss: 2.4411 - val_acc: 0.1774\n",
      "Epoch 22/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.6196 - acc: 0.4531 - val_loss: 2.3181 - val_acc: 0.2419\n",
      "Epoch 23/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.7034 - acc: 0.2969 - val_loss: 2.2684 - val_acc: 0.2258\n",
      "Epoch 24/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.3948 - acc: 0.4375 - val_loss: 2.3280 - val_acc: 0.2581\n",
      "Epoch 25/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.5049 - acc: 0.3438 - val_loss: 2.2758 - val_acc: 0.2581\n",
      "Epoch 26/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 1.3901 - acc: 0.4062 - val_loss: 2.4290 - val_acc: 0.2258\n",
      "Epoch 27/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3759 - acc: 0.4844 - val_loss: 2.2317 - val_acc: 0.2419\n",
      "Epoch 28/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2432 - acc: 0.4844 - val_loss: 2.2284 - val_acc: 0.2419\n",
      "Epoch 29/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.4123 - acc: 0.4219 - val_loss: 2.2253 - val_acc: 0.2419\n",
      "Epoch 30/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.4802 - acc: 0.3750 - val_loss: 2.2419 - val_acc: 0.2742\n",
      "Epoch 31/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.4280 - acc: 0.3906 - val_loss: 2.2833 - val_acc: 0.2742\n",
      "Epoch 32/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2043 - acc: 0.4844 - val_loss: 2.3344 - val_acc: 0.2258\n",
      "Epoch 33/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.1723 - acc: 0.5312 - val_loss: 2.2941 - val_acc: 0.2097\n",
      "Epoch 34/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.1276 - acc: 0.5312 - val_loss: 2.2651 - val_acc: 0.2419\n",
      "Epoch 35/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.4346 - acc: 0.3906 - val_loss: 2.3540 - val_acc: 0.2258\n",
      "Epoch 36/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.2449 - acc: 0.5156 - val_loss: 2.2438 - val_acc: 0.2097\n",
      "Epoch 37/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0848 - acc: 0.5938 - val_loss: 2.2373 - val_acc: 0.2258\n",
      "Epoch 38/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.2083 - acc: 0.5469 - val_loss: 2.2829 - val_acc: 0.2258\n",
      "Epoch 39/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1090 - acc: 0.5781 - val_loss: 2.3728 - val_acc: 0.2097\n",
      "Epoch 40/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1809 - acc: 0.5781 - val_loss: 2.3395 - val_acc: 0.2419\n",
      "Epoch 41/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9813 - acc: 0.6875 - val_loss: 2.3519 - val_acc: 0.2742\n",
      "Epoch 42/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.8813 - acc: 0.6719 - val_loss: 2.5766 - val_acc: 0.2581\n",
      "Epoch 43/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1629 - acc: 0.4844 - val_loss: 2.3206 - val_acc: 0.1935\n",
      "Epoch 44/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2196 - acc: 0.5625 - val_loss: 2.2503 - val_acc: 0.2742\n",
      "Epoch 45/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 98s 2s/step - loss: 1.1721 - acc: 0.5312 - val_loss: 2.3640 - val_acc: 0.2258\n",
      "Epoch 46/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8899 - acc: 0.6562 - val_loss: 2.3087 - val_acc: 0.2581\n",
      "Epoch 47/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0558 - acc: 0.5781 - val_loss: 2.3016 - val_acc: 0.2742\n",
      "Epoch 48/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0402 - acc: 0.5938 - val_loss: 2.2828 - val_acc: 0.1935\n",
      "Epoch 49/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0483 - acc: 0.5156 - val_loss: 2.4251 - val_acc: 0.2903\n",
      "Epoch 50/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0712 - acc: 0.5469 - val_loss: 2.4358 - val_acc: 0.2742\n",
      "Epoch 51/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0353 - acc: 0.5625 - val_loss: 2.4980 - val_acc: 0.2258\n",
      "Epoch 52/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0762 - acc: 0.6094 - val_loss: 2.2433 - val_acc: 0.2258\n",
      "Epoch 53/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9401 - acc: 0.6250 - val_loss: 2.4795 - val_acc: 0.2097\n",
      "Epoch 54/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.8538 - acc: 0.6719 - val_loss: 2.5565 - val_acc: 0.2419\n",
      "Epoch 55/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.7635 - acc: 0.6875 - val_loss: 2.4049 - val_acc: 0.2258\n",
      "Epoch 56/60\n",
      "32/64 [==============>...............] - ETA: 21s - loss: 1.1080 - acc: 0.4688Batch: 8/96\n",
      "Batch: 9/96\n",
      "Train on 64 samples, validate on 62 samples\n",
      "Epoch 1/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.7953 - acc: 0.1719 - val_loss: 2.1391 - val_acc: 0.2581\n",
      "Epoch 2/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 2.1871 - acc: 0.2969 - val_loss: 2.1199 - val_acc: 0.2581\n",
      "Epoch 3/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 2.0141 - acc: 0.2969 - val_loss: 2.1410 - val_acc: 0.1935\n",
      "Epoch 4/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 2.0765 - acc: 0.2812 - val_loss: 2.1315 - val_acc: 0.1935\n",
      "Epoch 5/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.9252 - acc: 0.2500 - val_loss: 2.1197 - val_acc: 0.2419\n",
      "Epoch 6/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.7080 - acc: 0.3906 - val_loss: 2.1710 - val_acc: 0.3226\n",
      "Epoch 7/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.7846 - acc: 0.2969 - val_loss: 2.1722 - val_acc: 0.2419\n",
      "Epoch 8/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.8492 - acc: 0.3125 - val_loss: 2.2441 - val_acc: 0.2419\n",
      "Epoch 9/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.6602 - acc: 0.3750 - val_loss: 2.1487 - val_acc: 0.3226\n",
      "Epoch 10/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.7102 - acc: 0.3594 - val_loss: 2.1423 - val_acc: 0.2097\n",
      "Epoch 11/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.7772 - acc: 0.3281 - val_loss: 2.1434 - val_acc: 0.2097\n",
      "Epoch 12/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.8244 - acc: 0.3281 - val_loss: 2.1751 - val_acc: 0.2097\n",
      "Epoch 13/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.5818 - acc: 0.4375 - val_loss: 2.1660 - val_acc: 0.2581\n",
      "Epoch 14/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.4471 - acc: 0.4375 - val_loss: 2.1602 - val_acc: 0.2903\n",
      "Epoch 15/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3470 - acc: 0.5781 - val_loss: 2.2648 - val_acc: 0.3065\n",
      "Epoch 16/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.4143 - acc: 0.4375 - val_loss: 2.2203 - val_acc: 0.2419\n",
      "Epoch 17/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.5077 - acc: 0.3906 - val_loss: 2.1641 - val_acc: 0.2742\n",
      "Epoch 18/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3493 - acc: 0.4688 - val_loss: 2.3295 - val_acc: 0.2903\n",
      "Epoch 19/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2917 - acc: 0.4688 - val_loss: 2.2581 - val_acc: 0.2581\n",
      "Epoch 20/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.5424 - acc: 0.3906 - val_loss: 2.1766 - val_acc: 0.3065\n",
      "Epoch 21/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.3050 - acc: 0.5000 - val_loss: 2.3094 - val_acc: 0.3065\n",
      "Epoch 22/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.3108 - acc: 0.4688 - val_loss: 2.3134 - val_acc: 0.2581\n",
      "Epoch 23/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0720 - acc: 0.6406 - val_loss: 2.3459 - val_acc: 0.3710\n",
      "Epoch 24/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0729 - acc: 0.5938 - val_loss: 2.4247 - val_acc: 0.2742\n",
      "Epoch 25/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2911 - acc: 0.4688 - val_loss: 2.4313 - val_acc: 0.3387\n",
      "Epoch 26/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.1514 - acc: 0.6094 - val_loss: 2.4198 - val_acc: 0.3226\n",
      "Epoch 27/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2514 - acc: 0.5156 - val_loss: 2.3116 - val_acc: 0.3387\n",
      "Epoch 28/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.2481 - acc: 0.5312 - val_loss: 2.2964 - val_acc: 0.2419\n",
      "Epoch 29/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1447 - acc: 0.5938 - val_loss: 2.4054 - val_acc: 0.3065\n",
      "Epoch 30/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1943 - acc: 0.5469 - val_loss: 2.4550 - val_acc: 0.2419\n",
      "Epoch 31/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.1775 - acc: 0.5625 - val_loss: 2.3628 - val_acc: 0.2742\n",
      "Epoch 32/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9910 - acc: 0.6250 - val_loss: 2.4749 - val_acc: 0.3387\n",
      "Epoch 33/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.1255 - acc: 0.5469 - val_loss: 2.3534 - val_acc: 0.2903\n",
      "Epoch 34/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9380 - acc: 0.6094 - val_loss: 2.4124 - val_acc: 0.2097\n",
      "Epoch 35/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0544 - acc: 0.5625 - val_loss: 2.6105 - val_acc: 0.2581\n",
      "Epoch 36/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9753 - acc: 0.5938 - val_loss: 2.4589 - val_acc: 0.2903\n",
      "Epoch 37/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 1.0199 - acc: 0.6094 - val_loss: 2.4658 - val_acc: 0.3387\n",
      "Epoch 38/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8241 - acc: 0.7500 - val_loss: 2.3726 - val_acc: 0.2903\n",
      "Epoch 39/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8842 - acc: 0.6250 - val_loss: 2.4666 - val_acc: 0.2742\n",
      "Epoch 40/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8345 - acc: 0.7344 - val_loss: 2.5919 - val_acc: 0.3387\n",
      "Epoch 41/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.9102 - acc: 0.6719 - val_loss: 2.7348 - val_acc: 0.2903\n",
      "Epoch 42/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8858 - acc: 0.6719 - val_loss: 2.7309 - val_acc: 0.3065\n",
      "Epoch 43/60\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.8221 - acc: 0.7656 - val_loss: 2.6472 - val_acc: 0.2903\n",
      "Epoch 44/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.1015 - acc: 0.5938 - val_loss: 2.3983 - val_acc: 0.1935\n",
      "Epoch 45/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 1.0800 - acc: 0.5625 - val_loss: 2.4324 - val_acc: 0.2742\n",
      "Epoch 46/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.9755 - acc: 0.6250 - val_loss: 2.5633 - val_acc: 0.2742\n",
      "Epoch 47/60\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.9962 - acc: 0.6562 - val_loss: 2.5424 - val_acc: 0.2903\n",
      "Epoch 48/60\n",
      "64/64 [==============================] - 98s 2s/step - loss: 0.7872 - acc: 0.7344 - val_loss: 2.7144 - val_acc: 0.2903\n",
      "Epoch 49/60\n",
      "32/64 [==============>...............] - ETA: 21s - loss: 0.6688 - acc: 0.6875"
     ]
    }
   ],
   "source": [
    "model, errorLog, dset, dset_test, tar, tar_test = tarrain(40000, 1724, 64, return_data=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bn_model = Xception(include_top=False, weights='imagenet', pooling='max')\n",
    "\n",
    "first = bn_model.output\n",
    "for layer in bn_model.layers:\n",
    "    layer.trainable = train_bottle\n",
    "        \n",
    "model = Dense(256, activation='relu')(first)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(10, activation='sigmoid')(model)\n",
    "    \n",
    "model_ = Model(inputs=[bn_model.input], outputs=model)\n",
    "\n",
    "model_.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
