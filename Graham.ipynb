{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41173 images belonging to 96 classes.\n",
      "Found 4105 images belonging to 96 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 1 layers into a model with 16 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-52a94a25e31e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;31m# model2.save('my_model.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# import numpy as np\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                          \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                          \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 1 layers into a model with 16 layers."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Activation, BatchNormalization, UpSampling2D, Input\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import applications\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "# train_data_dir = 'data/Trainers'\n",
    "# validation_data_dir = 'data/Images'\n",
    "train_data_dir = 'Trainers'\n",
    "validation_data_dir = 'Images'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=128,\n",
    "        class_mode=None)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=128,\n",
    "        class_mode=None)\n",
    "\n",
    "model = applications.VGG16(include_top=False, weights='imagenet',  input_shape = (256,256,3))\n",
    "\n",
    "x = model.output\n",
    "x = Flatten(name='flatten', input_shape = (256,256,3))(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(96, activation='softmax', name='predictions')(x)\n",
    "\n",
    "for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "model2 = Model([model.input], x)\n",
    "# model2 = multi_gpu_model(model2)\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# hist = model2.fit_generator(\n",
    "#          train_generator,\n",
    "#         epochs=10, steps_per_epoch=1288, shuffle=True,\n",
    "#         validation_data=validation_generator, validation_steps=10)\n",
    "\n",
    "# model2.save('my_model.h5')\n",
    "model2.load_weights('my_model_weights.h5')\n",
    "\n",
    "# import numpy as np\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Activation, BatchNormalization, UpSampling2D, Input\n",
    "# from keras.utils import multi_gpu_model\n",
    "# from keras import applications\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img_width, img_height = 256, 256\n",
    "\n",
    "# train_data_dir = 'data/Trainers'\n",
    "# validation_data_dir = 'data/Images'\n",
    "\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         train_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=128,\n",
    "#         class_mode=None)\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#         validation_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=128,\n",
    "#         class_mode=None)\n",
    "\n",
    "# model = applications.VGG16(include_top=False, weights='imagenet',  input_shape = (256,256,3))\n",
    "\n",
    "# x = model.output\n",
    "# x = Flatten(name='flatten')(x)\n",
    "# x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "# x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "# x = Dense(96, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# for layer in model.layers:\n",
    "#         layer.trainable = False\n",
    "\n",
    "# model2 = Model([model.input], x)\n",
    "# # model2 = multi_gpu_model(model2)\n",
    "# model2.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# # hist = model2.fit_generator(\n",
    "# #          train_generator,\n",
    "# #         epochs=10, steps_per_epoch=1288, shuffle=True,\n",
    "# #         validation_data=validation_generator, validation_steps=10)\n",
    "\n",
    "# model2.load_weights('my_model_weights.h5')\n",
    "\n",
    "# # model2.save_weights('my_model_weights.h5')\n",
    "\n",
    "# # plt.plot(hist.history['acc'])\n",
    "# # plt.plot(hist.history['val_acc'])\n",
    "# # plt.title('model accuracy')\n",
    "# # plt.ylabel('accuracy')\n",
    "# # plt.xlabel('epoch')\n",
    "# # plt.legend(['train', 'test'], loc='upper left')\n",
    "# # plt.savefig('model1.png', dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
