{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "import math\n",
    "import collections\n",
    "from PIL import Image\n",
    "from dropbox import DropboxOAuth2FlowNoRedirect\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pypyodbc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import concatenate, Input, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical  #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pypyodbc.connect(\"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "                      \"Server=028-GUMUS1-SRV;\"\n",
    "                      \"Database=KOTON_DB;\"\n",
    "                      \"Trusted_Connection=yes;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token='0DQLcsXIojcAAAAAAAgybeB3DOmXKK7bRTLyYwkthbrAiGmpQR4AuGINQkjBXhif'\n",
    "dbx = dropbox.Dropbox(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_image_df = pd.read_excel('C:/Users/Recep/Koton/Data/retrieved_image_list.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set(codes, indexes):\n",
    "    \"\"\"Takes list of option codes as input and returns related dataset, response set (sales amount)\n",
    "    and genuine option codes that included in e-commerce table.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(codes)>2000:\n",
    "        numOfBatches = 100\n",
    "    else:\n",
    "        numOfBatches = 1\n",
    "    \n",
    "    string_tar = \"Select OptionCode, TTSales = ISNULL(sum(TotalSales), 0) \\\n",
    "    from (Select CODE, TotalSales \\\n",
    "    From ( \\\n",
    "    SELECT [CODE], TotalSales=Sum(isnull(cast(totalqty as float),0)) \\\n",
    "      FROM [KOTON_DB].[dbo].[FA_Sales_Ecommerce] Group by CODE)t) AS Sales INNER JOIN [KOTON_DB].[dbo].[LU_Variant_New] AS Variant ON Variant.SkuCode = Sales.Code \\\n",
    "    Where \"\n",
    "    \n",
    "    codes_split = np.array_split(codes, numOfBatches)\n",
    "    indexes_split = np.array_split(indexes, numOfBatches)\n",
    "    \n",
    "    # to prevent empty targets\n",
    "    gen_codes = []\n",
    "    gen_indexes = []\n",
    "    target = []\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        _ =[]\n",
    "        flag2 = True\n",
    "        for i in codes_split[batch]:\n",
    "            if flag2:\n",
    "                _.append(\"OptionCode='\"+i+\"'\")\n",
    "                flag2 = False\n",
    "            else:\n",
    "                 _.append(\" OR OptionCode='\"+i+\"'\")\n",
    "        query2 = string_tar + ''.join(_) + \" Group by OptionCode\"\n",
    "        temp = pd.read_sql_query(query2, cnxn, index_col='optioncode')\n",
    "        target.append(temp)\n",
    "    target = pd.concat(target)\n",
    "\n",
    "    for code, index in zip(codes, indexes):\n",
    "        try:\n",
    "            target.loc[code]\n",
    "            gen_codes.append(code)\n",
    "            gen_indexes.append(index)\n",
    "        except:\n",
    "            pass        \n",
    "        \n",
    "    \n",
    "    string_inp = \"SELECT DISTINCT OptionCode, ProductHierarchyLevel02, ProductHierarchyLevel03, ProductHierarchyLevel04, ProductHierarchyLevel05, SeasonCode, KOLEKSÄ°YON, [KULLANIM-eski], [MODEL TASARIMI], [OZEL KOLEKSIYON], SEZONU \\\n",
    "  FROM [KOTON_DB].[dbo].[LU_Model_New] AS Model \\\n",
    "  INNER JOIN [KOTON_DB].[dbo].[LU_Variant_New] AS Variant ON Variant.ItemCode = Model.ItemCode \\\n",
    "  WHERE \"\n",
    "    \n",
    "#     numOfBatches = max(min(len(gen_indexes), numOfBatches), 1)\n",
    "    numOfBatches = min(len(gen_indexes), numOfBatches)\n",
    "    gen_codes_splited = np.array_split(gen_codes, numOfBatches)\n",
    "    dataset = []\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        _ =[]\n",
    "        flag1 = True\n",
    "        for i in gen_codes_splited[batch]:\n",
    "            if flag1:\n",
    "                _.append(\"OptionCode='\"+i+\"'\")\n",
    "                flag1 = False\n",
    "            else:\n",
    "                 _.append(\" OR OptionCode='\"+i+\"'\")\n",
    "        query1 = string_inp + ''.join(_)\n",
    "        dataset.append(pd.read_sql_query(query1, cnxn, index_col='optioncode'))\n",
    "    \n",
    "    dataset = pd.concat(dataset)\n",
    "    \n",
    "    \n",
    "    return dataset, target, gen_codes, gen_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 50\n",
    "startIndex = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages_n_train(numberSamples, startIndex, batchSize=64):\n",
    "    errorLog = []\n",
    "    bn_model = Xception(include_top=False, weights='imagenet')\n",
    "    \n",
    "    first_input = Input(shape=(10, 10, 2048))\n",
    "    first = Flatten()(first_input)\n",
    "    \n",
    "    second_input = Input(shape=(10,)) # number of features=10 !!!Change it after word2vec\n",
    "    second = Dense(10, activation='relu')(second_input)\n",
    "    \n",
    "    model = concatenate([first, second], axis=1)\n",
    "    model = Dense(256, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(256, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(1, activation='relu')(model)\n",
    "    \n",
    "    model_ = Model(inputs=[first_input, second_input], outputs=model)\n",
    "\n",
    "    model_.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    codes = []\n",
    "    idx = []\n",
    "    for picture_index in range(startIndex,startIndex + numberSamples):\n",
    "        code = retrieved_image_df.iloc[picture_index].name\n",
    "        codes.append(code)\n",
    "        idx.append(picture_index)\n",
    "    \n",
    "    dset, tar, gen_codes, gen_indexes = data_set(codes, idx)\n",
    "    dset = dset.apply(LabelEncoder().fit_transform)\n",
    "#     dset = pd.get_dummies(dset)\n",
    "    print(dset.shape)\n",
    "        \n",
    "    if batchSize>len(dset):\n",
    "        batchSize = len(dset)\n",
    "        print('Batch size is automatically adjusted.')\n",
    "    \n",
    "    numOfBatches, lastBatch = divmod(len(dset), batchSize-1)\n",
    "    dsets = np.array_split(dset, numOfBatches)\n",
    "    tars = np.array_split(tar, numOfBatches)\n",
    "    gen_codes = np.array_split(gen_codes, numOfBatches)\n",
    "    gen_indexes = np.array_split(gen_indexes, numOfBatches)\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        pic1 =[]\n",
    "        print('Batch: '+str(batch+1)+'/'+str(numOfBatches))\n",
    "        for code, picture_index in zip(gen_codes[batch], gen_indexes[batch]):\n",
    "            im_index = retrieved_image_df.iloc[picture_index]['image1'+'_index']        \n",
    "            if (math.isnan(float(im_index))==False):\n",
    "                filename = str(code).lower()+'_'+'image1'+'_'+str(int(im_index))+'.jpg'\n",
    "                path = '/Koton_Image_Files/'+filename\n",
    "                try:\n",
    "                    md, res = dbx.files_download(path)\n",
    "                    temp_pic = cv2.resize(cv2.imdecode(np.frombuffer(res.content, dtype=np.uint8), -1), (299,299))\n",
    "                    assert temp_pic.shape == (299, 299, 3)\n",
    "                    pic1.append(temp_pic)\n",
    "                except:\n",
    "                    errorLog.append(str(im_index)+'NAN value')\n",
    "                    batch += 1 #ignore defective batch\n",
    "                    continue\n",
    "            else:\n",
    "                errorLog.append(path+' Not found')\n",
    "                batch += 1 #ignore defective batch\n",
    "                continue\n",
    "        pic1 = np.array(pic1)\n",
    "        bottleneck_features = bn_model.predict(pic1)\n",
    "        model_.fit([bottleneck_features, dsets[batch]], tars[batch],\n",
    "              epochs=10)\n",
    "      \n",
    "    return model_, errorLog\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 10)\n",
      "Batch size is automatically adjusted.\n",
      "Batch: 1/1\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 5s 129ms/step - loss: 9196.5419 - mean_absolute_error: 68.6840\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 76.4390 - mean_absolute_error: 3.3659\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 76.4390 - mean_absolute_error: 3.3659\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 76.4390 - mean_absolute_error: 3.3659\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 76.4390 - mean_absolute_error: 3.3659\n",
      "Epoch 6/10\n",
      "32/41 [======================>.......] - ETA: 0s - loss: 9.1562 - mean_absolute_error: 1.6562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-13bd1a06361d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetImages_n_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1724\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-f4f7acc65162>\u001b[0m in \u001b[0;36mgetImages_n_train\u001b[1;34m(numberSamples, startIndex, batchSize)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mbottleneck_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         model_.fit([bottleneck_features, dsets[batch]], tars[batch],\n\u001b[1;32m---> 69\u001b[1;33m               epochs=10)\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorLog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, errorLog = getImages_n_train(900, 1724, 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
