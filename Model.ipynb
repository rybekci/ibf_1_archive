{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "import math\n",
    "import collections\n",
    "from PIL import Image\n",
    "from dropbox import DropboxOAuth2FlowNoRedirect\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pypyodbc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import concatenate, Input, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical  #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pypyodbc.connect(\"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "                      \"Server=028-GUMUS1-SRV;\"\n",
    "                      \"Database=KOTON_DB;\"\n",
    "                      \"Trusted_Connection=yes;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token='0DQLcsXIojcAAAAAAAgybeB3DOmXKK7bRTLyYwkthbrAiGmpQR4AuGINQkjBXhif'\n",
    "dbx = dropbox.Dropbox(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_image_df = pd.read_excel('C:/Users/Recep/Koton/Data/retrieved_image_list.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set(codes, indexes):\n",
    "    \"\"\"Takes list of option codes as input and returns related dataset, response set (sales amount)\n",
    "    and genuine option codes that included in e-commerce table.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(codes)>2000:\n",
    "        numOfBatches = 100\n",
    "    else:\n",
    "        numOfBatches = 1\n",
    "    \n",
    "    string_tar = \"Select OptionCode, TTSales = ISNULL(sum(TotalSales), 0) \\\n",
    "    from (Select CODE, TotalSales \\\n",
    "    From ( \\\n",
    "    SELECT [CODE], TotalSales=Sum(isnull(cast(totalqty as float),0)) \\\n",
    "      FROM [KOTON_DB].[dbo].[FA_Sales_Ecommerce] Group by CODE)t) AS Sales INNER JOIN [KOTON_DB].[dbo].[LU_Variant_New] AS Variant ON Variant.SkuCode = Sales.Code \\\n",
    "    Where \"\n",
    "    \n",
    "    codes_split = np.array_split(codes, numOfBatches)\n",
    "    indexes_split = np.array_split(indexes, numOfBatches)\n",
    "    \n",
    "    # to prevent empty targets\n",
    "    gen_codes = []\n",
    "    gen_indexes = []\n",
    "    target = []\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        _ =[]\n",
    "        flag2 = True\n",
    "        for i in codes_split[batch]:\n",
    "            if flag2:\n",
    "                _.append(\"OptionCode='\"+i+\"'\")\n",
    "                flag2 = False\n",
    "            else:\n",
    "                 _.append(\" OR OptionCode='\"+i+\"'\")\n",
    "        query2 = string_tar + ''.join(_) + \" Group by OptionCode\"\n",
    "        temp = pd.read_sql_query(query2, cnxn, index_col='optioncode')\n",
    "        target.append(temp)\n",
    "    target = pd.concat(target)\n",
    "\n",
    "    for code, index in zip(codes, indexes):\n",
    "        try:\n",
    "            target.loc[code]\n",
    "            gen_codes.append(code)\n",
    "            gen_indexes.append(index)\n",
    "        except:\n",
    "            pass        \n",
    "        \n",
    "    \n",
    "    string_inp = \"SELECT DISTINCT OptionCode, ProductHierarchyLevel02, ProductHierarchyLevel03, ProductHierarchyLevel04, ProductHierarchyLevel05, SeasonCode, KOLEKSÄ°YON, [KULLANIM-eski], [MODEL TASARIMI], [OZEL KOLEKSIYON], SEZONU \\\n",
    "  FROM [KOTON_DB].[dbo].[LU_Model_New] AS Model \\\n",
    "  INNER JOIN [KOTON_DB].[dbo].[LU_Variant_New] AS Variant ON Variant.ItemCode = Model.ItemCode \\\n",
    "  WHERE \"\n",
    "    \n",
    "#     numOfBatches = max(min(len(gen_indexes), numOfBatches), 1)\n",
    "    numOfBatches = max(min(len(gen_indexes), numOfBatches), 1)\n",
    "    gen_codes_splited = np.array_split(gen_codes, numOfBatches)\n",
    "    dataset = []\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        _ =[]\n",
    "        flag1 = True\n",
    "        for i in gen_codes_splited[batch]:\n",
    "            if flag1:\n",
    "                _.append(\"OptionCode='\"+i+\"'\")\n",
    "                flag1 = False\n",
    "            else:\n",
    "                 _.append(\" OR OptionCode='\"+i+\"'\")\n",
    "        query1 = string_inp + ''.join(_)\n",
    "        dataset.append(pd.read_sql_query(query1, cnxn, index_col='optioncode'))\n",
    "    \n",
    "    dataset = pd.concat(dataset)\n",
    "    \n",
    "    \n",
    "    return dataset, target, gen_codes, gen_indexes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "codes = ['6KAK45005AA001',\n",
    " '6KAK45005AA616',\n",
    " '6KAK45007AA040',\n",
    " '6KAK45007AA480',\n",
    " '6KAK45007AA999',\n",
    " '6KAK45009AA060',\n",
    " '6KAK45009AA480',\n",
    " '6KAK45020OA040',\n",
    " '6KAK45020OA999',\n",
    " '6KAK46000IW418']\n",
    "idx = [0, 1 , 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "dset, tar, gen_codes, gen_indexes = data_set(codes, idx)\n",
    "# dset.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 50\n",
    "startIndex = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages_n_train(numberSamples, startIndex, batchSize=64):\n",
    "    errorLog = []\n",
    "    bn_model = Xception(include_top=False, weights='imagenet')\n",
    "    \n",
    "    first_input = Input(shape=(10, 10, 2048))\n",
    "    first = Flatten()(first_input)\n",
    "    \n",
    "    second_input = Input(shape=(10,)) # number of features=10 !!!Change it after word2vec\n",
    "    second = Dense(10, activation='relu')(second_input)\n",
    "    \n",
    "    model = concatenate([first, second], axis=1)\n",
    "    model = Dense(256, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(256, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(1, activation='relu')(model)\n",
    "    \n",
    "    model_ = Model(inputs=[first_input, second_input], outputs=model)\n",
    "\n",
    "    model_.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    codes = []\n",
    "    idx = []\n",
    "    for picture_index in range(startIndex,startIndex + numberSamples):\n",
    "        code = retrieved_image_df.iloc[picture_index].name\n",
    "        codes.append(code)\n",
    "        idx.append(picture_index)\n",
    "    \n",
    "    dset, tar, gen_codes, gen_indexes = data_set(codes, idx)\n",
    "    dset = dset.apply(LabelEncoder().fit_transform)\n",
    "    print(dset.shape)\n",
    "       \n",
    "    if batchSize>numberSamples:\n",
    "        batchSize = numberSamples\n",
    "        print('Batch size is automatically adjusted.')\n",
    "    \n",
    "    numOfBatches, lastBatch = divmod(numberSamples, batchSize)\n",
    "    dsets = np.array_split(dset, numOfBatches)\n",
    "    tars = np.array_split(tar, numOfBatches)\n",
    "    gen_codes = np.array_split(gen_codes, numOfBatches)\n",
    "    gen_indexes = np.array_split(gen_indexes, numOfBatches)\n",
    "    \n",
    "    for batch in range(numOfBatches):\n",
    "        pic1 =[]\n",
    "        print('Batch: '+str(batch+1)+'/'+str(numOfBatches))\n",
    "        for code, picture_index in zip(gen_codes[batch], gen_indexes[batch]):\n",
    "            im_index = retrieved_image_df.iloc[picture_index]['image1'+'_index']        \n",
    "            if (math.isnan(float(im_index))==False):\n",
    "                filename = str(code).lower()+'_'+'image1'+'_'+str(int(im_index))+'.jpg'\n",
    "                path = '/Koton_Image_Files/'+filename\n",
    "                try:\n",
    "                    md, res = dbx.files_download(path)\n",
    "                    temp_pic = cv2.resize(cv2.imdecode(np.frombuffer(res.content, dtype=np.uint8), -1), (299,299))\n",
    "                    assert temp_pic.shape == (299, 299, 3)\n",
    "                    pic1.append(temp_pic)\n",
    "                except:\n",
    "                    errorLog.append(path+' Not found')\n",
    "                    batch += 1 #ignore defective batch\n",
    "        pic1 = np.array(pic1)\n",
    "        bottleneck_features = bn_model.predict(pic1)\n",
    "        model_.fit([bottleneck_features, dsets[batch]], tars[batch],\n",
    "              epochs=10)\n",
    "      \n",
    "    return model_, errorLog\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51810, 10)\n",
      "Batch: 1/1406\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 29s 777ms/step - loss: 1908.7610 - mean_absolute_error: 16.5266\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 2s 59ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 8140.7044 - mean_absolute_error: 18.3504\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 2s 60ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 2s 57ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 2s 57ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 84.5946 - mean_absolute_error: 3.6216\n",
      "Batch: 2/1406\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 2s 59ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 2s 57ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 9.4595 - mean_absolute_error: 2.1081\n",
      "Batch: 3/1406\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 2s 57ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 22.4865 - mean_absolute_error: 2.8108\n",
      "Batch: 4/1406\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 2s 57ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 2s 60ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 2s 57ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 150.3243 - mean_absolute_error: 3.7297\n",
      "Batch: 5/1406\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 18.7027 - mean_absolute_error: 2.1622\n",
      "Batch: 6/1406\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 34.5676 - mean_absolute_error: 3.2703\n",
      "Batch: 7/1406\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 2s 56ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 5.9459 - mean_absolute_error: 1.7297\n",
      "Batch: 8/1406\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All input arrays (x) should have the same number of samples. Got array shapes: [(36, 10, 10, 2048), (37, 10)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-64e680826a26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetImages_n_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m90000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1724\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-196-fd8367f228a2>\u001b[0m in \u001b[0;36mgetImages_n_train\u001b[1;34m(numberSamples, startIndex, batchSize)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mbottleneck_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         model_.fit([bottleneck_features, dsets[batch]], tars[batch],\n\u001b[1;32m---> 63\u001b[1;33m               epochs=10)\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorLog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    802\u001b[0m             ]\n\u001b[0;32m    803\u001b[0m             \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[1;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    226\u001b[0m         raise ValueError('All input arrays (x) should have '\n\u001b[0;32m    227\u001b[0m                          \u001b[1;34m'the same number of samples. Got array shapes: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                          str([x.shape for x in inputs]))\n\u001b[0m\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         raise ValueError('All target arrays (y) should have '\n",
      "\u001b[1;31mValueError\u001b[0m: All input arrays (x) should have the same number of samples. Got array shapes: [(36, 10, 10, 2048), (37, 10)]"
     ]
    }
   ],
   "source": [
    "model, errorLog = getImages_n_train(90000, 1724, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 10)\n",
      "Batch: 1/31\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_80 to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-20d352f326e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetImages_n_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-196-fd8367f228a2>\u001b[0m in \u001b[0;36mgetImages_n_train\u001b[1;34m(numberSamples, startIndex, batchSize)\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m#ignore defective batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mpic1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mbottleneck_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         model_.fit([bottleneck_features, dsets[batch]], tars[batch],\n\u001b[0;32m     63\u001b[0m               epochs=10)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_80 to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "model, errorLog = getImages_n_train(2000, 0, 64) # excelde image1 bos olanlar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
